{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teller_boston.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKJGj4IzMMBB",
        "colab_type": "text"
      },
      "source": [
        "# Illustrating the `teller`\n",
        "\n",
        "This notebook illustrates the use of the [`teller`](https://github.com/thierrymoudiki/teller), a model-agnostic tool for Machine Learning explainability. Two models are used: a linear model and a [Random Forest](https://en.wikipedia.org/wiki/Random_forest) (here, the _black-box_ model). The most straightforward way to illustrate the `teller` is to use a linear model. In this case, the effects of model covariates on the response can be directly related to the linear model's coefficients.\n",
        "\n",
        "Currently, the `teller` can be installed from Github as: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0x4rfI9MByJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8f49a765-1026-412a-a97e-99195232f2e2"
      },
      "source": [
        "pip install git+https://github.com/thierrymoudiki/teller.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/thierrymoudiki/teller.git\n",
            "  Cloning https://github.com/thierrymoudiki/teller.git to /tmp/pip-req-build-54wbobzk\n",
            "  Running command git clone -q https://github.com/thierrymoudiki/teller.git /tmp/pip-req-build-54wbobzk\n",
            "Requirement already satisfied (use --upgrade to upgrade): teller==0.1.0 from git+https://github.com/thierrymoudiki/teller.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: teller\n",
            "  Building wheel for teller (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for teller: filename=teller-0.1.0-py2.py3-none-any.whl size=9119 sha256=ed591690821ca4691e5ff0921e417b60b922fccb12512edfbd57bf9380d2657b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a416_fr3/wheels/d9/51/a6/69fa991f7529be33ba87e6e684fdc936eb67a827aa7a2bbfcf\n",
            "Successfully built teller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUZwnL7NM8ri",
        "colab_type": "text"
      },
      "source": [
        "Data for the demo is Boston Housing dataset. The response is MEDV, Median value of owner-occupied homes in $1000’s (the __reponse__):\n",
        "\n",
        "\n",
        "\n",
        "- CRIM per capita crime rate by town\n",
        "- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "- INDUS proportion of non-retail business acres per town\n",
        "- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "- NOX nitric oxides concentration (parts per 10 million)\n",
        "- RM average number of rooms per dwelling\n",
        "- AGE proportion of owner-occupied units built prior to 1940\n",
        "- DIS weighted distances to five Boston employment centres\n",
        "- RAD index of accessibility to radial highways\n",
        "- TAX full-value property-tax rate per $10,000\n",
        "\n",
        "- PTRATIO pupil-teacher ratio by town\n",
        "- LSTAT % lower status of the population\n",
        "- MEDV Median value of owner-occupied homes in $1000’s (the __reponse__)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4X01QkpNDWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import teller as tr\n",
        "import pandas as pd\n",
        "import numpy as np      \n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# import data\n",
        "boston = datasets.load_boston()\n",
        "X = np.delete(boston.data, 11, 1)\n",
        "y = boston.target\n",
        "col_names = np.append(np.delete(boston.feature_names, 11), 'MEDV')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChTdmrmHNIUS",
        "colab_type": "text"
      },
      "source": [
        "Split data into a training and a testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGFLkh4FNLnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7cb85895-3e41-435a-8603-b0293292f385"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
        "                                                    random_state=123)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 12)\n",
            "(102, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY_Da35hNp1P",
        "colab_type": "text"
      },
      "source": [
        "As we said before, the most straightforward way to illustrate the `teller` is to use a linear model. In this case, the effects of model covariates on the response can be directly related to the linear model's coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYO0oiBJNmiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f75979aa-6224-4482-aceb-2deec27081c8"
      },
      "source": [
        "# fit a linear regression model \n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train, y_train)\n",
        "print(col_names)\n",
        "print(regr.coef_) # these will be compared to effects \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'LSTAT' 'MEDV']\n",
            "[-1.01154624e-01  4.76941400e-02  6.25165481e-02  1.47253911e+00\n",
            " -1.61503638e+01  4.19880279e+00  1.85740482e-03 -1.37739515e+00\n",
            "  2.62817392e-01 -1.28645883e-02 -8.92383870e-01 -5.72958247e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxXANPvJO6mX",
        "colab_type": "text"
      },
      "source": [
        "Now, using the `teller`, we can obtain a similar result. Notice that there's no heterogeneity in the effects of covariates on the response, and that the effects are equal to linear model's coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah4ELhu6PO9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "039dc36f-2bcb-4b72-a7cd-23bebf8544c9"
      },
      "source": [
        "# creating the explainer (needs a data frame, for column names)\n",
        "df_test = pd.DataFrame(data = np.column_stack((X_test, y_test)), \n",
        "                       columns = col_names)\n",
        "expr = tr.Explainer(obj=regr, df=df_test, target='MEDV')\n",
        "\n",
        "# fitting the explainer\n",
        "expr.fit()\n",
        "\n",
        "# model effects, to be compared to regr.coef_\n",
        "print(expr.effects_)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              mean           std        min        max\n",
            "NOX     -16.150364  4.653454e-10 -16.150364 -16.150364\n",
            "DIS      -1.377395  7.876549e-11  -1.377395  -1.377395\n",
            "PTRATIO  -0.892384  1.272029e-11  -0.892384  -0.892384\n",
            "LSTAT    -0.572958  2.521022e-11  -0.572958  -0.572958\n",
            "CRIM     -0.101155  3.162134e-09  -0.101155  -0.101155\n",
            "TAX      -0.012865  7.018682e-13  -0.012865  -0.012865\n",
            "AGE       0.001857  5.350552e-12   0.001857   0.001857\n",
            "ZN        0.047694  1.182888e-11   0.047694   0.047694\n",
            "INDUS     0.062517  3.562424e-11   0.062517   0.062517\n",
            "RAD       0.262817  5.098845e-11   0.262817   0.262817\n",
            "CHAS      1.472539  8.301885e-11   1.472539   1.472539\n",
            "RM        4.198803  5.172671e-11   4.198803   4.198803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejQD_HQvRBxM",
        "colab_type": "text"
      },
      "source": [
        "__All else held constant__, homes values are mostly affected by air pollution here, with a decrease of 16k\\$ observed for an increase of 10 million parts in concentration of nitric oxides. The number of rooms drives the increase in homes values, with an increase of 4k\\$ each time a room is added. What story does  Random Forest (here, the _black-box_ model) model tells us here?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXdQVSDMRAp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "90667a11-ae81-472c-8578-cb41fd77c329"
      },
      "source": [
        "# fit a linear regression model \n",
        "regr2 = RandomForestRegressor(n_estimators=1000, random_state=123)\n",
        "regr2.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# creating the explainer\n",
        "df_test = pd.DataFrame(data = np.column_stack((X_test, y_test)), \n",
        "                       columns = col_names)\n",
        "expr = tr.Explainer(obj=regr2, df=df_test, target='MEDV')\n",
        "\n",
        "\n",
        "# fitting the explainer\n",
        "expr.fit()\n",
        "\n",
        "\n",
        "# heterogeneity of effects\n",
        "print(expr.effects_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              mean         std          min          max\n",
            "LSTAT   -11.541770  104.111356  -680.369720   335.990384\n",
            "PTRATIO  -5.795078   26.975073  -155.914653    56.827716\n",
            "INDUS    -3.425733   26.951393  -258.382895     0.000000\n",
            "TAX      -0.052272    0.824834    -6.479723     4.839278\n",
            "CHAS      0.000000    0.000000     0.000000     0.000000\n",
            "AGE       0.970438    5.204533    -7.242999    39.647849\n",
            "ZN        1.043840   11.672871   -28.280289    83.808739\n",
            "NOX       1.286747  325.585815 -1258.347012  1937.006074\n",
            "DIS       2.014293   20.343364     0.000000   205.457901\n",
            "RAD      18.420244  192.075879  -247.710558  1791.773035\n",
            "RM       28.570050  146.327113  -123.772764  1126.812921\n",
            "CRIM     72.200382  585.402432     0.000000  5685.533164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdRGlnl1SWm0",
        "colab_type": "text"
      },
      "source": [
        "Here, home values decrease most when the percentage of \"lower\" status population increases, or when there are not enough teachers for each kid in the area. __All else held constant__, the number or rooms is still an important driver for an increase. The distance to highways and employment centers also play an important role here. Conversely, what is said about the criminality rate is rather surprising. \n",
        "\n",
        "__(Very) Important__: Typically, these interpretability numbers would be coupled with __model's accuracy__ (and other performance considerations for production)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e35LQ77PUqgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c748ce46-add2-4e67-d409-306ca6f16fee"
      },
      "source": [
        "# accuracy of linear model \n",
        "print(np.sqrt(np.mean((regr.predict(X_test) - y_test)**2)))\n",
        "\n",
        "# accuracy of Random Forest\n",
        "print(np.sqrt(np.mean((regr2.predict(X_test) - y_test)**2)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.431091875823595\n",
            "4.322189349251635\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}